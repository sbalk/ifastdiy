{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeremy heeft cats n dogs opnieuw gedaan met bijna alleen maar technieken die we tot nu toe hebben geleerd.\n",
    "* Cats n dogs\n",
    "    * Basics:\n",
    "        * dogscats-ensemble.ipynb\n",
    "        * Seperate vgg at boundary conv layers - dense layers, and before last layer.\n",
    "        * calculate outputs for training set at both places as precalc_mid en precalc_ll\n",
    "        * train last layer on precalc_ll\n",
    "        * replace trained last layer on vgg dense part\n",
    "        * Train dense part with with precalc_mid\n",
    "        * replace dense part on entire vgg\n",
    "        * Train dense part on entire set with data augmentation\n",
    "    * Extras, add batchnorm to vgg dense part:\n",
    "        * imagenet_batchnorm.ipynb\n",
    "        * add because you can use less dropout\n",
    "        * You CAN'T just stick batchnorm in pre trained network because it will change the weights for the next layer. What a batchnorm layer does is subtract mean and devide by standard deviation. What you CAN do is add a batchnorm layer that has mean and sd of the entire set it was originally trained on for that particular layer in the net. For the dense part of vgg that goes as follows:\n",
    "        * Calculate var and mu at the locations of the places where you will insert the two batchnorm layers (after the first two Dense layers)\n",
    "        * Create two batchnorm layers and insert them after the Dense layers\n",
    "        * Set the weights of the bn layers to the vars and mus\n",
    "        * Check if the predictions are still the same\n",
    "        * Extra: because the original net wasn't trained with batchnorm, it didn't take advantage of the fact it had it. You can retrain the new batchnormed dense part on the entire imagenet training set to improve the features. Done with pre computed conv layer it took less than an hour.\n",
    "        * You can now increase your learning rates because bn normalizes the activations, they won't escalate.\n",
    "* Collaborative filtering (INSANE)\n",
    "    * Check what the embeddings say about the movies. Embeddings are factors that calculate the rating for the movie, similar to weights in a nn. Embeddings are made up of bias terms and latent factors (OR embeddings and latent factors are the same and biast terms just add up OR multiply the entire latent factors of an input). Check lesson4.ipynb for how to implement the recommendation set data for a neural network\n",
    "        * If you just check the movies with the highest bias terms it gives  you some form of a normalized general rating, adjusted for the kinds of users there are.\n",
    "        * If you look at the latent factors, it is not necessarily clear what it is. You can apply PCA, to get three columns which and sort the best and worst of each PCA component.\n",
    "    * Keras functional API (versus sequential)\n",
    "        * With the functional model you can re-create the same thing a Sequential model does but you can also create different streams of data within the same model such as movies and users.\n",
    "        * A functional model starts with an input layer\n",
    "        * The first layer then is made and immediately after that, the inputs from the previous layer is called.\n",
    "        * The same goes for all following layers but now you can have dat from an old layer move into a layer a couple of steps further. I think.\n",
    "        * In the example of movie ratings:\n",
    "            * create a model that takes movie/user input and give it n_factors/variables, possibly with regularization.\n",
    "            * create a model that takes input and add bias how?\n",
    "            * merge them\n",
    "            * compile them\n",
    "            * fit them\n",
    "\n",
    "\n",
    "\n",
    "Wat doet de functie 'embedding'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
