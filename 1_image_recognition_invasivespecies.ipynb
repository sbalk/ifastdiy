{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Memo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Install kaggle-cli, set competition `kg -c 'compname'` and download dataset `kg download`\n",
    "* move all `cat*` to `cats/`, same for dogs\n",
    "* take 1000 random pictures and move them to valid/cats/ with `shuf -n 1000 -e train/cat* | xargs -i mv {} valid/cats/`, same for dogs\n",
    "Furthermore use\n",
    "* `ls /train/cats/ | wc -l` to count files in `/train/cats/`\n",
    "* `ls /train/cats/ | grep -v 'cat'` to find all files that DON'T have cat in it. `-v`-flag inverts search.\n",
    "* use: `mv /train/cat* /valid/cats` and `cp` to do the rest\n",
    "* copy utils etc: `cp -t ~/fastai/ vgg16.py vgg16bn.py utils.py resnet50.py`\n",
    "\n",
    "* sending files over scp:\n",
    "`scp -i ~/.ssh/aws-key-fast-ai.pem ./zip.zip ubuntu@ec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action plan\n",
    "1. Initiate\n",
    "2. Create train subdirectories and order images in labeled directories\n",
    "3. Create valid and sample directories\n",
    "4. Finetune and train model\n",
    "5. Generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import csv\n",
    "import shutil\n",
    "import glob\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import math\n",
    "from keras.preprocessing import image\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "\n",
    "# Set directories\n",
    "current_dir = os.getcwd()\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "LESSON_HOME_DIR = os.path.abspath(current_dir)\n",
    "DATA_HOME_DIR = os.path.abspath(current_dir+'/data/invasiveplants')\n",
    "results_path=DATA_HOME_DIR + '/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 2. create train subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove all folders created by this script (not test/ and backup/)\n",
    "%rm -r $DATA_HOME_DIR/results/\n",
    "%rm -r $DATA_HOME_DIR/valid/\n",
    "%rm -r $DATA_HOME_DIR/sample/\n",
    "%rm -r $DATA_HOME_DIR/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create directories\n",
    "%mkdir -p $DATA_HOME_DIR/train/invasive/\n",
    "%mkdir -p $DATA_HOME_DIR/train/non_invasive/\n",
    "%mkdir -p $DATA_HOME_DIR/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def list_pictures_by_label(csvfile):\n",
    "    plantfile = []\n",
    "    both = []\n",
    "    labels = []\n",
    "    with open(DATA_HOME_DIR+'/'+csvfile+'.csv', 'rb') as f:\n",
    "        train_labels = csv.reader(f, delimiter=' ')\n",
    "        temp = next(train_labels)\n",
    "        for row in train_labels:\n",
    "            both.append(row)\n",
    "            plantfile.append(int(row[0][:-2]))\n",
    "            labels.append(int(row[0][-1:]))\n",
    "    invasive = [str(plantfile[i])+'.jpg' for i,x in enumerate(labels) if x==1]\n",
    "    non_invasive = [str(plantfile[i])+'.jpg' for i,x in enumerate(labels) if x==0]\n",
    "    return invasive, non_invasive\n",
    "\n",
    "def copy_files_from_train_to_trainlabel(invasive, non_invasive):\n",
    "    for i in range(len(invasive)):\n",
    "        shutil.move(DATA_HOME_DIR+'/backup/train_unordered/'+invasive[i], DATA_HOME_DIR+'/train/invasive/')\n",
    "    for j in range(len(non_invasive)):\n",
    "        shutil.move(DATA_HOME_DIR+'/backup/train_unordered/'+non_invasive[j], DATA_HOME_DIR+'/train/non_invasive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "copy_files_from_train_to_trainlabel(*list_pictures_by_label('train_labels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3. Create valid and sample directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create directories\n",
    "%mkdir -p $DATA_HOME_DIR/valid/invasive\n",
    "%mkdir -p $DATA_HOME_DIR/valid/non_invasive\n",
    "%mkdir -p $DATA_HOME_DIR/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def move_from_train_to_valid():\n",
    "    dirs = os.listdir(DATA_HOME_DIR+'/train')\n",
    "    print(dirs)\n",
    "    for iterator in dirs:\n",
    "        if os.listdir(DATA_HOME_DIR+'/valid/'+iterator+'/') == []:\n",
    "            g = glob.glob(DATA_HOME_DIR+'/train/'+iterator+'/'+'*.jpg')\n",
    "            shuf = np.random.permutation(g)\n",
    "            for i in range(int(math.ceil(0.08*len(g)))):\n",
    "#                 print(DATA_HOME_DIR+'/valid/'+iterator+'/'+ os.path.basename(shuf[i]))\n",
    "                shutil.move(shuf[i], DATA_HOME_DIR+'/valid/'+iterator+'/'+ os.path.basename(shuf[i]))\n",
    "        else:\n",
    "            print('/valid/'+ str(iterator)+ 'folder not empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['non_invasive', 'invasive']\n"
     ]
    }
   ],
   "source": [
    "move_from_train_to_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create directories\n",
    "%mkdir -p $DATA_HOME_DIR/sample/results/\n",
    "%mkdir -p $DATA_HOME_DIR/sample/valid/invasive\n",
    "%mkdir -p $DATA_HOME_DIR/sample/valid/non_invasive\n",
    "%mkdir -p $DATA_HOME_DIR/sample/train/invasive/\n",
    "%mkdir -p $DATA_HOME_DIR/sample/train/non_invasive/\n",
    "%mkdir -p $DATA_HOME_DIR/sample/test/unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_samplefolder():\n",
    "    dirs = os.listdir(DATA_HOME_DIR+'/train')\n",
    "    if os.listdir(DATA_HOME_DIR+'/sample/train/'+dirs[0]+'/') == []:\n",
    "        for iterator in dirs:\n",
    "            g = glob.glob(DATA_HOME_DIR+'/train/'+iterator+'/'+'*.jpg')\n",
    "            shuf = np.random.permutation(g)\n",
    "            for i in range(20):\n",
    "                shutil.copyfile(shuf[i], DATA_HOME_DIR+'/sample/train/'+iterator+'/'+ os.path.basename(shuf[i]))\n",
    "            for i in range(10):\n",
    "                shutil.copyfile(shuf[i], DATA_HOME_DIR+'/sample/valid/'+iterator+'/'+ os.path.basename(shuf[i]))\n",
    "        g = glob.glob(DATA_HOME_DIR+'/test/unknown/'+'*.jpg')\n",
    "        shuf = np.random.permutation(g)\n",
    "        for i in range(10):\n",
    "                    shutil.copyfile(shuf[i+20], DATA_HOME_DIR+'/sample/test/unknown/'+ os.path.basename(shuf[i+20]))\n",
    "    else:\n",
    "        print('Sample folder not empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "create_samplefolder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Finetune and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = DATA_HOME_DIR + '/sample/'\n",
    "# path = DATA_HOME_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Found 10 images belonging to 1 classes.\n",
      "finetune done\n",
      "Running epoch 0\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - 24s - loss: 1.1780 - acc: 0.6000 - val_loss: 0.6268 - val_acc: 0.6500\n",
      "fit done\n",
      "Running epoch 1\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - 24s - loss: 1.1124 - acc: 0.6000 - val_loss: 0.4414 - val_acc: 0.7500\n",
      "fit done\n",
      "Completed 2 fit operations\n"
     ]
    }
   ],
   "source": [
    "import vgg16stijn; reload(vgg16stijn)\n",
    "from vgg16stijn import Vgg16Stijn\n",
    "vgg = Vgg16Stijn()\n",
    "\n",
    "batches = vgg.batch_iterator(path+'train', batch_size=batch_size)\n",
    "val_batches = vgg.batch_iterator(path+'valid', batch_size=batch_size*2)\n",
    "test_batches = vgg.batch_iterator(path+'test', batch_size=batch_size)\n",
    "\n",
    "vgg.finetune_to_classes(batches)\n",
    "print('finetune done')\n",
    "vgg.fit_n_save(batches, val_batches, nb_epoch, results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vgg16stijn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting vgg16stijn.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile vgg16stijn.py\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, ZeroPadding2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Lambda\n",
    "from keras.optimizers import Adam #, SGD, RMSprop\n",
    "\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3,1,1))\n",
    "def RGB_to_BGR(x):\n",
    "    x = x - vgg_mean\n",
    "    return x[:, ::-1] # reverse axis rgb->bgr\n",
    "        \n",
    "class Vgg16Stijn():\n",
    "    def __init__(self): # sets up neural network\n",
    "        self.FILE_PATH = 'http://files.fast.ai/models/'\n",
    "        self.create()\n",
    "        self.get_classes()\n",
    "    \n",
    "    def create(self): # build actual network\n",
    "        \"\"\"\n",
    "            Builds neural network and loads pretrained vgg16 model weights\n",
    "        \"\"\"\n",
    "        model = self.model = Sequential()\n",
    "        model.add(Lambda(RGB_to_BGR, input_shape=(3,224,224), output_shape=(3,224,224))) #change rgb to bgr\n",
    "        \n",
    "        self.add_convlayers(2, 64)\n",
    "        self.add_convlayers(2, 128)\n",
    "        self.add_convlayers(3, 256)\n",
    "        self.add_convlayers(3, 512)\n",
    "        self.add_convlayers(3, 512)\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        self.add_fullconnect()\n",
    "        self.add_fullconnect()\n",
    "        model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "        fname = 'vgg16.h5'\n",
    "        model.load_weights(get_file(fname, self.FILE_PATH+fname, cache_subdir='models'))\n",
    "    \n",
    "    def add_convlayers(self, layers, filters):\n",
    "        \"\"\"\n",
    "            Adds a specified number of ZeroPadding (line of zeros around image) and Covolution layers\n",
    "            to the model, and a MaxPooling (outputs max value of group) layer at the very end.\n",
    "\n",
    "            Args:\n",
    "                layers (int):   The number of zero padded convolution layers\n",
    "                                to be added to the model.\n",
    "                filters (int):  The number of convolution filters to be \n",
    "                                created for each layer. I think these are the \n",
    "                                number of learnable features per layer\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        for i in range(layers):\n",
    "            model.add(ZeroPadding2D((1, 1)))\n",
    "            model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    def add_fullconnect(self):\n",
    "        \"\"\"\n",
    "            Adds a fully connected layer of 4096 neurons (with 64x64 dimension) to the model with a\n",
    "            Dropout of 0.5. Dropout is random 0.5 of the input nodes are set to 0 to prevent overfitting.\n",
    "\n",
    "            Args:   None\n",
    "            Returns:   None\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        model.add(Dense(4096, activation='relu')) # fully connected layer with 64x64 dimension\n",
    "        model.add(Dropout(0.5)) # random half of the input nodes are set to 0 to prevent overfitting\n",
    "    \n",
    "    def get_classes(self):\n",
    "        fname = 'imagenet_class_index.json'\n",
    "        fpath = get_file(fname, self.FILE_PATH+fname, cache_subdir='models')\n",
    "        with open(fpath) as f:\n",
    "            class_dict = json.load(f)\n",
    "        self.classes = [class_dict[str(i)][1] for i in range(len(class_dict))]\n",
    "        \n",
    "    def batch_iterator(self, path, gen=image.ImageDataGenerator(), shuffle=True, batch_size=8, class_mode='categorical'):\n",
    "        return gen.flow_from_directory(directory=path, target_size=(224,224),\n",
    "                    class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)\n",
    "\n",
    "    def change_number_outputnodes(self, num):\n",
    "        model = self.model\n",
    "        model.pop()\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "        model.add(Dense(num,activation='softmax'))\n",
    "        self.compile()\n",
    "        \n",
    "    def compile(self, lr=0.001):\n",
    "        \"\"\"\n",
    "            Configures the model for training.\n",
    "            See Keras documentation: https://keras.io/models/model/\n",
    "        \"\"\"\n",
    "        self.model.compile(optimizer=Adam(lr=lr),\n",
    "                loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    def finetune_to_classes(self, batches):\n",
    "        \"\"\"\n",
    "            Adjusts final layer to correct number of output nodes and updates class labels.\n",
    "            \n",
    "            Args:\n",
    "                batches: keras.preprocessing.image.ImageDataGenerator opbject with flow_from_directory()\n",
    "        \"\"\"\n",
    "        self.change_number_outputnodes(batches.nb_class)\n",
    "        classes = list(iter(batches.class_indices)) \n",
    "        # creates list of classes from dict item 'batches.class_indices'\n",
    "        # batches.class_indices i.e. {'invasive': 1, 'non_invasive': 0}\n",
    "        for key in batches.class_indices:\n",
    "            classes[batches.class_indices[key]] = key\n",
    "        # orders class keys by value in dict like ['non_invasive', 'invasive'] because key 'non_invasive' has value 0\n",
    "        self.classes = classes\n",
    "        \n",
    "    def fit(self, batches, val_batches, nb_epoch=1):\n",
    "        \"\"\"\n",
    "            Fits the model on data yielded batch-by-batch by a Python generator.\n",
    "            See Keras documentation: https://keras.io/models/model/\n",
    "        \"\"\"\n",
    "        self.model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=nb_epoch,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "        print('fit done')\n",
    "    \n",
    "    def fit_n_save(self, batches, val_batches, nb_epoch, results_path, extra_info=''):\n",
    "        \"\"\"\n",
    "            Uses fit and saves weights every epoch\n",
    "            \n",
    "            Args:\n",
    "                batches, val_batches, nb_epoch\n",
    "                extra_info: string attached to filename\n",
    "        \"\"\"\n",
    "        extra_info = str(extra_info)\n",
    "        latest_weights_filename = None\n",
    "        for epoch in range(nb_epoch):\n",
    "            print('Epoch %d' %epoch)\n",
    "            self.fit(batches, val_batches, nb_epoch=1)\n",
    "            latest_weights_filename = 'ft%d%s.h5' %(epoch+1, extra_info)\n",
    "            self.model.save_weights(results_path+latest_weights_filename)\n",
    "        print \"Completed %s fit operations\" % nb_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### vgg16.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %load vgg16.py\n",
    "from __future__ import division, print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# In case we are going to use the TensorFlow backend we need to explicitly set the Theano image ordering\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3,1,1))\n",
    "def vgg_preprocess(x):\n",
    "    \"\"\"\n",
    "        Subtracts the mean RGB value, and transposes RGB to BGR.\n",
    "        The mean RGB was computed on the image set used to train the VGG model.\n",
    "\n",
    "        Args: \n",
    "            x: Image array (height x width x channels)\n",
    "        Returns:\n",
    "            Image array (height x width x transposed_channels)\n",
    "    \"\"\"\n",
    "    x = x - vgg_mean\n",
    "    return x[:, ::-1] # reverse axis rgb->bgr\n",
    "\n",
    "\n",
    "class Vgg16():\n",
    "    \"\"\"\n",
    "        The VGG 16 Imagenet model\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        self.FILE_PATH = 'http://files.fast.ai/models/'\n",
    "        self.create()\n",
    "        self.get_classes()\n",
    "\n",
    "\n",
    "    def get_classes(self):\n",
    "        \"\"\"\n",
    "            Downloads the Imagenet classes index file and loads it to self.classes.\n",
    "            The file is downloaded only if it not already in the cache.\n",
    "        \"\"\"\n",
    "        fname = 'imagenet_class_index.json'\n",
    "        fpath = get_file(fname, self.FILE_PATH+fname, cache_subdir='models')\n",
    "        with open(fpath) as f:\n",
    "            class_dict = json.load(f)\n",
    "        self.classes = [class_dict[str(i)][1] for i in range(len(class_dict))]\n",
    "\n",
    "    def predict(self, imgs, details=False):\n",
    "        \"\"\"\n",
    "            Predict the labels of a set of images using the VGG16 model.\n",
    "\n",
    "            Args:\n",
    "                imgs (ndarray)    : An array of N images (size: N x width x height x channels).\n",
    "                details : ??\n",
    "            \n",
    "            Returns:\n",
    "                preds (np.array) : Highest confidence value of the predictions for each image.\n",
    "                idxs (np.ndarray): Class index of the predictions with the max confidence.\n",
    "                classes (list)   : Class labels of the predictions with the max confidence.\n",
    "        \"\"\"\n",
    "        # predict probability of each class for each image\n",
    "        all_preds = self.model.predict(imgs)\n",
    "        # for each image get the index of the class with max probability\n",
    "        idxs = np.argmax(all_preds, axis=1)\n",
    "        # get the values of the highest probability for each image\n",
    "        preds = [all_preds[i, idxs[i]] for i in range(len(idxs))]\n",
    "        # get the label of the class with the highest probability for each image\n",
    "        classes = [self.classes[idx] for idx in idxs]\n",
    "        return np.array(preds), idxs, classes\n",
    "\n",
    "\n",
    "    def ConvBlock(self, layers, filters):\n",
    "        \"\"\"\n",
    "            Adds a specified number of ZeroPadding and Covolution layers\n",
    "            to the model, and a MaxPooling layer at the very end.\n",
    "\n",
    "            Args:\n",
    "                layers (int):   The number of zero padded convolution layers\n",
    "                                to be added to the model.\n",
    "                filters (int):  The number of convolution filters to be \n",
    "                                created for each layer.\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        for i in range(layers):\n",
    "            model.add(ZeroPadding2D((1, 1)))\n",
    "            model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "\n",
    "    def FCBlock(self):\n",
    "        \"\"\"\n",
    "            Adds a fully connected layer of 4096 neurons to the model with a\n",
    "            Dropout of 0.5\n",
    "\n",
    "            Args:   None\n",
    "            Returns:   None\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        model.add(Dense(4096, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "    def create(self):\n",
    "        \"\"\"\n",
    "            Creates the VGG16 network achitecture and loads the pretrained weights.\n",
    "\n",
    "            Args:   None\n",
    "            Returns:   None\n",
    "        \"\"\"\n",
    "        model = self.model = Sequential()\n",
    "        model.add(Lambda(vgg_preprocess, input_shape=(3,224,224), output_shape=(3,224,224)))\n",
    "\n",
    "        self.ConvBlock(2, 64)\n",
    "        self.ConvBlock(2, 128)\n",
    "        self.ConvBlock(3, 256)\n",
    "        self.ConvBlock(3, 512)\n",
    "        self.ConvBlock(3, 512)\n",
    "\n",
    "        model.add(Flatten())\n",
    "        self.FCBlock()\n",
    "        self.FCBlock()\n",
    "        model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "        fname = 'vgg16.h5'\n",
    "        model.load_weights(get_file(fname, self.FILE_PATH+fname, cache_subdir='models'))\n",
    "\n",
    "\n",
    "    def get_batches(self, path, gen=image.ImageDataGenerator(), shuffle=True, batch_size=8, class_mode='categorical'):\n",
    "        \"\"\"\n",
    "            Takes the path to a directory, and generates batches of augmented/normalized data. Yields batches indefinitely, in an infinite loop.\n",
    "\n",
    "            See Keras documentation: https://keras.io/preprocessing/image/\n",
    "        \"\"\"\n",
    "        return gen.flow_from_directory(path, target_size=(224,224),\n",
    "                class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)\n",
    "\n",
    "\n",
    "    def ft(self, num):\n",
    "        \"\"\"\n",
    "            Replace the last layer of the model with a Dense (fully connected) layer of num neurons.\n",
    "            Will also lock the weights of all layers except the new layer so that we only learn\n",
    "            weights for the last layer in subsequent training.\n",
    "\n",
    "            Args:\n",
    "                num (int) : Number of neurons in the Dense layer\n",
    "            Returns:\n",
    "                None\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        model.pop()\n",
    "        for layer in model.layers: layer.trainable=False\n",
    "        model.add(Dense(num, activation='softmax'))\n",
    "        self.compile()\n",
    "\n",
    "    def finetune(self, batches):\n",
    "        \"\"\"\n",
    "            Modifies the original VGG16 network architecture and updates self.classes for new training data.\n",
    "            \n",
    "            Args:\n",
    "                batches : A keras.preprocessing.image.ImageDataGenerator object.\n",
    "                          See definition for get_batches().\n",
    "        \"\"\"\n",
    "        self.ft(batches.nb_class)\n",
    "        classes = list(iter(batches.class_indices)) # get a list of all the class labels\n",
    "        # batches.class_indices is a dict with the class name as key and an index as value\n",
    "        # eg. {'cats': 0, 'dogs': 1}\n",
    "\n",
    "        # sort the class labels by index according to batches.class_indices and update model.classes\n",
    "        for c in batches.class_indices:\n",
    "            classes[batches.class_indices[c]] = c\n",
    "        self.classes = classes\n",
    "\n",
    "\n",
    "    def compile(self, lr=0.001):\n",
    "        \"\"\"\n",
    "            Configures the model for training.\n",
    "            See Keras documentation: https://keras.io/models/model/\n",
    "        \"\"\"\n",
    "        self.model.compile(optimizer=Adam(lr=lr),\n",
    "                loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    def fit_data(self, trn, labels,  val, val_labels,  nb_epoch=1, batch_size=64):\n",
    "        \"\"\"\n",
    "            Trains the model for a fixed number of epochs (iterations on a dataset).\n",
    "            See Keras documentation: https://keras.io/models/model/\n",
    "        \"\"\"\n",
    "        self.model.fit(trn, labels, nb_epoch=nb_epoch,\n",
    "                validation_data=(val, val_labels), batch_size=batch_size)\n",
    "\n",
    "\n",
    "    def fit(self, batches, val_batches, nb_epoch=1):\n",
    "        \"\"\"\n",
    "            Fits the model on data yielded batch-by-batch by a Python generator.\n",
    "            See Keras documentation: https://keras.io/models/model/\n",
    "        \"\"\"\n",
    "        self.model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=nb_epoch,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "\n",
    "\n",
    "    def test(self, path, batch_size=8):\n",
    "        \"\"\"\n",
    "            Predicts the classes using the trained model on data yielded batch-by-batch.\n",
    "\n",
    "            Args:\n",
    "                path (string):  Path to the target directory. It should contain one subdirectory \n",
    "                                per class.\n",
    "                batch_size (int): The number of images to be considered in each batch.\n",
    "            \n",
    "            Returns:\n",
    "                test_batches, numpy array(s) of predictions for the test_batches.\n",
    "    \n",
    "        \"\"\"\n",
    "        test_batches = self.get_batches(path, shuffle=False, batch_size=batch_size, class_mode=None)\n",
    "        return test_batches, self.model.predict_generator(test_batches, test_batches.nb_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ma code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = DATA_HOME_DIR\n",
    "# path = DATA_HOME_DIR + '/sample/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2111 images belonging to 2 classes.\n",
      "Found 184 images belonging to 2 classes.\n",
      "Found 1531 images belonging to 1 classes.\n",
      "Epoch 1/2\n",
      "  72/2111 [>.............................] - ETA: 828s - loss: 1.0159 - acc: 0.6528"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-58b8897c5542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtest_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'temptest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinetune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/fastai/vgg16.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, batches, val_batches, nb_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \"\"\"\n\u001b[1;32m    212\u001b[0m         self.model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=nb_epoch,\n\u001b[0;32m--> 213\u001b[0;31m                 validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    872\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1441\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1442\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1444\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import division,print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "import math\n",
    "\n",
    "import utils; reload(utils)\n",
    "from utils import plots\n",
    "import vgg16; reload(vgg16)\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "vgg = Vgg16()\n",
    "# Grab a few images at a time for training and validation.\n",
    "# NB: They must be in subdirectories named based on their category\n",
    "batches = vgg.get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(path+'valid', batch_size=batch_size*2)\n",
    "test_batches = vgg.get_batches(path+'temptest', batch_size=batch_size, shuffle=False)\n",
    "vgg.finetune(batches)\n",
    "vgg.fit(batches, val_batches, nb_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_dogness(test_batches):\n",
    "    imgs,nolabel = next(test_batches)\n",
    "    preds, idxs, labels = vgg.predict(imgs)\n",
    "    dogness = np.multiply(preds, idxs) + np.multiply(1.-preds, 1-idxs)\n",
    "    return dogness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_order_testset(testfolder):\n",
    "#     files_names = os.listdir(path+testfolder)\n",
    "    files_names = test_batches.filenames\n",
    "    files_names = [int(files_names[i][5:-4]) for i in range(len(files_names))]\n",
    "    N = int(math.ceil(len(files_names)/batch_size))\n",
    "#     predictions = [x for i in range(N) for x in batch_dogness(test_batches).tolist()]\n",
    "    predictions = [x for i in range(N) for x in batch_dogness(test_batches).clip(0.01,0.99).tolist()] #Use clipping because of log loss judgement by Kaggle\n",
    "    predictions_ordered = [x for (y,x) in sorted(zip(files_names,predictions))]\n",
    "    return predictions_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_csv(predictions_ordered):\n",
    "    with open(path+'test.csv', 'wb') as f:\n",
    "        fieldnames = ['id', 'label']\n",
    "        wr = csv.writer(f, delimiter=',')\n",
    "        wr.writerow(fieldnames)\n",
    "        for i in range(len(predictions_ordered)):\n",
    "            wr.writerow([i+1,predictions_ordered[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = predict_order_testset('temptest/test')\n",
    "write_csv(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %load utils.py\n",
    "from __future__ import division,print_function\n",
    "import math, os, json, sys, re\n",
    "import cPickle as pickle\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy.random import random, permutation, randn, normal, uniform, choice\n",
    "from numpy import newaxis\n",
    "import scipy\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy.ndimage import imread\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import bcolz\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from IPython.lib.display import FileLink\n",
    "\n",
    "import theano\n",
    "from theano import shared, tensor as T\n",
    "from theano.tensor.nnet import conv2d, nnet\n",
    "from theano.tensor.signal import pool\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional\n",
    "from keras.layers import TimeDistributed, Activation, SimpleRNN, GRU\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.regularizers import l2, activity_l2, l1, activity_l1\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.utils.layer_utils import layer_from_config\n",
    "from keras.metrics import categorical_crossentropy, categorical_accuracy\n",
    "from keras.layers.convolutional import *\n",
    "from keras.preprocessing import image, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from vgg16 import *\n",
    "from vgg16bn import *\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "\n",
    "\n",
    "to_bw = np.array([0.299, 0.587, 0.114])\n",
    "\n",
    "def gray(img):\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        return np.rollaxis(img, 0, 1).dot(to_bw)\n",
    "    else:\n",
    "        return np.rollaxis(img, 0, 3).dot(to_bw)\n",
    "\n",
    "def to_plot(img):\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        return np.rollaxis(img, 0, 1).astype(np.uint8)\n",
    "    else:\n",
    "        return np.rollaxis(img, 0, 3).astype(np.uint8)\n",
    "\n",
    "def plot(img):\n",
    "    plt.imshow(to_plot(img))\n",
    "\n",
    "\n",
    "def floor(x):\n",
    "    return int(math.floor(x))\n",
    "def ceil(x):\n",
    "    return int(math.ceil(x))\n",
    "\n",
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
    "\n",
    "\n",
    "def do_clip(arr, mx):\n",
    "    clipped = np.clip(arr, (1-mx)/1, mx)\n",
    "    return clipped/clipped.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "def get_batches(dirname, gen=image.ImageDataGenerator(), shuffle=True, batch_size=4, class_mode='categorical',\n",
    "                target_size=(224,224)):\n",
    "    return gen.flow_from_directory(dirname, target_size=target_size,\n",
    "            class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)\n",
    "\n",
    "\n",
    "def onehot(x):\n",
    "    return to_categorical(x)\n",
    "\n",
    "\n",
    "def wrap_config(layer):\n",
    "    return {'class_name': layer.__class__.__name__, 'config': layer.get_config()}\n",
    "\n",
    "\n",
    "def copy_layer(layer): return layer_from_config(wrap_config(layer))\n",
    "\n",
    "\n",
    "def copy_layers(layers): return [copy_layer(layer) for layer in layers]\n",
    "\n",
    "\n",
    "def copy_weights(from_layers, to_layers):\n",
    "    for from_layer,to_layer in zip(from_layers, to_layers):\n",
    "        to_layer.set_weights(from_layer.get_weights())\n",
    "\n",
    "\n",
    "def copy_model(m):\n",
    "    res = Sequential(copy_layers(m.layers))\n",
    "    copy_weights(m.layers, res.layers)\n",
    "    return res\n",
    "\n",
    "\n",
    "def insert_layer(model, new_layer, index):\n",
    "    res = Sequential()\n",
    "    for i,layer in enumerate(model.layers):\n",
    "        if i==index: res.add(new_layer)\n",
    "        copied = layer_from_config(wrap_config(layer))\n",
    "        res.add(copied)\n",
    "        copied.set_weights(layer.get_weights())\n",
    "    return res\n",
    "\n",
    "\n",
    "def adjust_dropout(weights, prev_p, new_p):\n",
    "    scal = (1-prev_p)/(1-new_p)\n",
    "    return [o*scal for o in weights]\n",
    "\n",
    "\n",
    "def get_data(path, target_size=(224,224)):\n",
    "    batches = get_batches(path, shuffle=False, batch_size=1, class_mode=None, target_size=target_size)\n",
    "    return np.concatenate([batches.next() for i in range(batches.nb_sample)])\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    (This function is copied from the scikit docs.)\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(cm)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "\n",
    "\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "\n",
    "\n",
    "def mk_size(img, r2c):\n",
    "    r,c,_ = img.shape\n",
    "    curr_r2c = r/c\n",
    "    new_r, new_c = r,c\n",
    "    if r2c>curr_r2c:\n",
    "        new_r = floor(c*r2c)\n",
    "    else:\n",
    "        new_c = floor(r/r2c)\n",
    "    arr = np.zeros((new_r, new_c, 3), dtype=np.float32)\n",
    "    r2=(new_r-r)//2\n",
    "    c2=(new_c-c)//2\n",
    "    arr[floor(r2):floor(r2)+r,floor(c2):floor(c2)+c] = img\n",
    "    return arr\n",
    "\n",
    "\n",
    "def mk_square(img):\n",
    "    x,y,_ = img.shape\n",
    "    maxs = max(img.shape[:2])\n",
    "    y2=(maxs-y)//2\n",
    "    x2=(maxs-x)//2\n",
    "    arr = np.zeros((maxs,maxs,3), dtype=np.float32)\n",
    "    arr[floor(x2):floor(x2)+x,floor(y2):floor(y2)+y] = img\n",
    "    return arr\n",
    "\n",
    "\n",
    "def vgg_ft(out_dim):\n",
    "    vgg = Vgg16()\n",
    "    vgg.ft(out_dim)\n",
    "    model = vgg.model\n",
    "    return model\n",
    "\n",
    "def vgg_ft_bn(out_dim):\n",
    "    vgg = Vgg16BN()\n",
    "    vgg.ft(out_dim)\n",
    "    model = vgg.model\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_classes(path):\n",
    "    batches = get_batches(path+'train', shuffle=False, batch_size=1)\n",
    "    val_batches = get_batches(path+'valid', shuffle=False, batch_size=1)\n",
    "    test_batches = get_batches(path+'test', shuffle=False, batch_size=1)\n",
    "    return (val_batches.classes, batches.classes, onehot(val_batches.classes), onehot(batches.classes),\n",
    "        val_batches.filenames, batches.filenames, test_batches.filenames)\n",
    "\n",
    "\n",
    "def split_at(model, layer_type):\n",
    "    layers = model.layers\n",
    "    layer_idx = [index for index,layer in enumerate(layers)\n",
    "                 if type(layer) is layer_type][-1]\n",
    "    return layers[:layer_idx+1], layers[layer_idx+1:]\n",
    "\n",
    "\n",
    "class MixIterator(object):\n",
    "    def __init__(self, iters):\n",
    "        self.iters = iters\n",
    "        self.multi = type(iters) is list\n",
    "        if self.multi:\n",
    "            self.N = sum([it[0].N for it in self.iters])\n",
    "        else:\n",
    "            self.N = sum([it.N for it in self.iters])\n",
    "\n",
    "    def reset(self):\n",
    "        for it in self.iters: it.reset()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def next(self, *args, **kwargs):\n",
    "        if self.multi:\n",
    "            nexts = [[next(it) for it in o] for o in self.iters]\n",
    "            n0 = np.concatenate([n[0] for n in nexts])\n",
    "            n1 = np.concatenate([n[1] for n in nexts])\n",
    "            return (n0, n1)\n",
    "        else:\n",
    "            nexts = [next(it) for it in self.iters]\n",
    "            n0 = np.concatenate([n[0] for n in nexts])\n",
    "            n1 = np.concatenate([n[1] for n in nexts])\n",
    "            return (n0, n1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
